{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load('../data/processed/train.npz')['x']\n",
    "y_train = np.load('../data/processed/train.npz')['y']\n",
    "X_v = np.load('../data/processed/v.npz')['x']\n",
    "y_v = np.load('../data/processed/v.npz')['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from src.utils.amex_metric import *\n",
    "\n",
    "with open('../config/xgboost.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dv = xgb.DMatrix(X_v, y_v)\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=9999, verbose_eval=0,\n",
    "                evals=[(dtrain, 'train'), (dv, 'v')], custom_metric=amex_scorer, \n",
    "                early_stopping_rounds=100, maximize=True)\n",
    "print(amex_metric(y_v, bst.predict(dv, iteration_range=(0, bst.best_iteration + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances --> top feature as same importance as bottom 100 features\n",
    "import pandas as pd\n",
    "\n",
    "dict_gain = bst.get_score(importance_type='gain')\n",
    "dict_weight = bst.get_score(importance_type='weight')\n",
    "for ix in range(188):\n",
    "    key = f'f{ix}'\n",
    "    if key not in dict_gain:\n",
    "        dict_gain[key] = 0\n",
    "        dict_weight[key] = 0\n",
    "df_importance = pd.DataFrame({'feature': dict_gain.keys(),\n",
    "                              'gain': dict_gain.values(),\n",
    "                              'weight': dict_weight.values()})\n",
    "df_importance.to_csv('../outputs/results/feature_importances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('axes', grid=True)\n",
    "plt.rcParams['grid.color'] = (0.5, 0.5, 0.5, 0.2)\n",
    "plt.rc('ytick', direction='out', color='gray')\n",
    "plt.rc('xtick', direction='out', color='gray')\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# DataIQ\n",
    "uncertainty = pd.read_csv('../outputs/results/aleatoric.csv')['0']\n",
    "confidence = pd.read_csv('../outputs/results/confidence.csv')['0']\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "ax.hexbin(uncertainty, confidence, mincnt=1, bins='log', gridsize=50)\n",
    "ax.set_xlabel('Aleatoric uncertainty')\n",
    "ax.set_ylabel('Confidence')\n",
    "plt.grid(False)\n",
    "fig.savefig('../outputs/figures/unc_vs_conf.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].hist(uncertainty, bins=30, edgecolor='dimgray', color='lightskyblue', lw=0.1)\n",
    "axes[0].set_xlabel('Aleatoric uncertainty')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='x')\n",
    "axes[0].set_ylim((0, 140000))\n",
    "axes[1].hist(confidence, bins=30, edgecolor='dimgray', color='lightskyblue', lw=0.1)\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].grid(axis='x')\n",
    "axes[1].set_ylim((0, 200000))\n",
    "fig.savefig('../outputs/figures/dataiq_hist.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide in Hard/Easy/Ambiguous\n",
    "uncertainty_thresh = 0.2\n",
    "thresh = 0.25\n",
    "conf_thresh_low = thresh\n",
    "conf_thresh_high = 1 - thresh\n",
    "conf_thresh = 0.5\n",
    "\n",
    "hard_train = np.where((confidence <= conf_thresh_low) & (uncertainty <= uncertainty_thresh))[0]\n",
    "easy_train = np.where((confidence >= conf_thresh_high) & (uncertainty <= uncertainty_thresh))[0]\n",
    "\n",
    "hard_easy = np.concatenate((hard_train, easy_train))\n",
    "ambig_train = []\n",
    "for id in range(len(confidence)):\n",
    "    if id not in hard_easy:\n",
    "        ambig_train.append(id)\n",
    "ambig_train = np.array(ambig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hard_train)) # Very few hard points --> overconfidence problem\n",
    "print(len(easy_train))\n",
    "print(len(ambig_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = pd.read_csv('../outputs/results/knn_100.csv')['0']\n",
    "knn_hard = knn[hard_train]\n",
    "knn_easy = knn[easy_train]\n",
    "knn_ambig = knn[ambig_train]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "min_v, max_v = -0.00003, 0.00001\n",
    "bin_width = (max_v - min_v) / 40\n",
    "bin_edges = np.arange(min_v, max_v + bin_width, bin_width)\n",
    "ax.hist(knn_hard, label='Hard', density=True, edgecolor='dimgray', color='sandybrown', lw=0.1, alpha=0.6, bins=bin_edges)\n",
    "ax.hist(knn_easy, label='Easy', density=True, edgecolor='dimgray', color='yellowgreen', lw=0.1, alpha=0.6, bins=bin_edges)\n",
    "ax.hist(knn_ambig, label='Ambiguous', density=True, edgecolor='dimgray', color='lightskyblue', lw=0.1, alpha=0.6, bins=bin_edges)\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(axis='x')\n",
    "ax.set_xlim((-0.00003, 0.00001))\n",
    "ax.set_xlabel('KNN Shapley')\n",
    "ax.set_ylabel('Density')\n",
    "fig.savefig('../outputs/figures/knn_vs_dataiq_hist.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hard = y_train[hard_train]\n",
    "y_easy = y_train[easy_train]\n",
    "y_ambig = y_train[ambig_train]\n",
    "\n",
    "X_hard = X_train[hard_train]\n",
    "X_easy = X_train[easy_train]\n",
    "X_ambig = X_train[ambig_train]\n",
    "\n",
    "print(y_hard.sum() / len(y_hard)) # High amount of defaulters\n",
    "print(y_easy.sum() / len(y_easy)) # Mostly non-defaulters\n",
    "print(y_ambig.sum() / len(y_ambig)) # High amount of defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the top 2 features (minus outliers)\n",
    "ambig_def = X_ambig[y_ambig == 1, :]\n",
    "easy_def = X_easy[y_easy == 1, :]\n",
    "hard_def = X_hard[y_hard == 1, :]\n",
    "\n",
    "ambig_nondef = X_ambig[y_ambig == 0, :]\n",
    "easy_nondef = X_easy[y_easy == 0, :]\n",
    "hard_nondef = X_hard[y_hard == 0, :]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Feature 0\n",
    "min_v, max_v = np.mean(ambig_def[:, 0]), np.mean(ambig_def[:, 0]) + 1.2\n",
    "bin_width = (max_v - min_v) / 30\n",
    "bin_edges = np.arange(min_v, max_v + bin_width, bin_width)\n",
    "axes[0].hist(ambig_def[:, 0], bins=bin_edges, edgecolor='dimgray', color='lightskyblue', lw=0.1, alpha=0.6, density=True, label='Ambiguous')\n",
    "axes[0].hist(hard_def[:, 0], bins=bin_edges, edgecolor='dimgray', color='sandybrown', lw=0.1, alpha=0.6, density=True, label='Hard')\n",
    "axes[0].hist(easy_def[:, 0], bins=bin_edges, edgecolor='dimgray', color='yellowgreen', lw=0.1, alpha=0.6, density=True, label='Easy')\n",
    "axes[0].set_xlabel('Feature 0 - defaulters')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].grid(axis='x')\n",
    "axes[0].legend(loc='upper left')\n",
    "axes[0].set_yticks([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5])\n",
    "axes[0].set_ylim([0, 3.6])\n",
    "\n",
    "axes[1].hist(ambig_nondef[:, 0], bins=bin_edges, edgecolor='dimgray', color='lightskyblue', lw=0.1, alpha=0.6, density=True)\n",
    "axes[1].hist(hard_nondef[:, 0], bins=bin_edges, edgecolor='dimgray', color='sandybrown', lw=0.1, alpha=0.6, density=True)\n",
    "axes[1].hist(easy_nondef[:, 0], bins=bin_edges, edgecolor='dimgray', color='yellowgreen', lw=0.1, alpha=0.6, density=True)\n",
    "axes[1].set_xlabel('Feature 0 - non-defaulters')\n",
    "axes[1].grid(axis='x')\n",
    "axes[1].set_yticks([0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5])\n",
    "axes[1].set_ylim([0, 3.6])\n",
    "\n",
    "fig.savefig('../outputs/figures/best_features_hist.pdf', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
